{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "## SIS 420                           ##\n",
        "## Alumno: Sanchez Calvimontes Pablo ##\n",
        "## Carrera: Ingenieria de Sistemas   ##\n",
        "## Grupo laboratorio:  Miercoles     ##\n",
        "#######################################\n",
        "\n",
        "#REPOSITORIO DE GITHUB\n",
        "# https://github.com/Pablo-SC/Sis420_SegundoParcial\n",
        "\n",
        "#INSTRUCCION DE ECAMPUS \n",
        "# 1. A partir del dataset que se le asigne de forma aleatoria, considerar generar datos \n",
        "# sinteticos si el valor de m es menor a 10000, posteriormente analize si el dataset corresponde a una regresion, \n",
        "# clasificacion binario o clasificacion multiclase y aplique el codigo correspondiente de los revisados en clase. \n",
        "# Se debe incluir una explicacion detallada de la resolucion del ejercicio.\n",
        "\n",
        "# EXPLICACION DEL CODIGO  \n",
        "\n",
        "# EL DATAset asignado es tortuga dataset, es de una empresa/ academia de software tiene originalmente mas de 20000 por lo que no fue necesario usar una \n",
        "# funcion para crear datos sinteticos\n",
        "\n",
        "# primero se verifico si se debia hacer un tratamiento de datos, para datos tipo str, tipo date, o datos null\t\n",
        "\n",
        "# Se elimino las primeras 3 columnas que no son relevantes para el caso\n",
        "\n",
        "# Existen 6 tipos de clasifaciones para Y\n",
        "\n",
        "# Despues de asignar los valores a las columnas X y Y se normalizo los datos y se aplico el tratamiento de datos \n",
        "# para que no existan valores null ni str ni datetime\n",
        "\n",
        "# tambien se uso una funcion para rellenar los valores que faltaban en algunas columnas y de esta  manera todas\n",
        "# las columnas tengas la misma cantidad de datos\n",
        "# depues se aplico el cuadernillo visto en clases de one vs all que se uso para clasificar el perfil del estudiante\n",
        "\n",
        "\n",
        "# Se uso la libreria pandas y numpy\n",
        "\n",
        "# la prediccion del conjunto es:\n",
        "\n",
        "# Precision del conjuto de entrenamiento: 70.32% \n",
        "\n"
      ],
      "metadata": {
        "id": "2wddEGFnyeP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7uUbHleaSAY"
      },
      "source": [
        "# Clasificación multiclase\n",
        "\n",
        "## Introduction\n",
        "\n",
        "En este ejercicio se implementa la regresion one-vs-all y una red neuronal para reconocimiento de digitos.\n",
        "\n",
        "Antes de empezar la ejecución de las partes de codigo correspondienters a los ejercicios, se requiere importar todas las librerias necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D-1z2kzraSAc"
      },
      "outputs": [],
      "source": [
        "# utilizado para la manipulación de directorios y rutas\n",
        "import os\n",
        "\n",
        "# Cálculo científico y vectorial para python\n",
        "import numpy as np\n",
        "\n",
        "# Libreria para graficos\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Modulo de optimizacion en scipy\n",
        "from scipy import optimize\n",
        "\n",
        "# modulo para cargar archivos en formato MATLAB\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "lzmV5mPCeh6c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8N16GR2aSAd"
      },
      "source": [
        "## 1 Clasificación multiclase\n",
        "\n",
        "Para este ejercicio, se usará regresión logística y redes neuronales para reconocer dígitos escritos a mano (de 0 a 9). El reconocimiento automático de dígitos escritos a mano se usa ampliamente en la actualidad, desde el reconocimiento de códigos postales (códigos postales) en sobres de correo hasta el reconocimiento de montos escritos en cheques bancarios. Este ejercicio  mostrará cómo los métodos que ha aprendido se pueden utilizar para esta tarea de clasificación.\n",
        "\n",
        "La primera parte del ejercicio, extenderá la implementación anterior de la regresión logística y la aplicará a la clasificación de uno contra todos (one vs all).\n",
        "\n",
        "### 1.1 Dataset\n",
        "\n",
        "Se proporciona un conjunto de datos en `ex3data1.mat` que contiene 5000 ejemplos de entrenamiento de dígitos escritos a mano (este es un subconjunto del conjunto de datos de dígitos escritos a mano [MNIST] http://yann.lecun.com/exdb/mnist)). El formato `.mat` significa que los datos se han guardado en un formato de matriz nativo Octave/MATLAB, en lugar de un formato de texto (ASCII) como un archivo csv. Usamos el formato `.mat` aquí para mostrar los diferentes formatos en los que se pueden presentar los datasets. Python proporciona mecanismos para cargar el formato nativo de MATLAB usando la función `loadmat` dentro del módulo` scipy.io`. Esta función devuelve un diccionario de Python con claves que contienen los nombres de las variables dentro del archivo `.mat`.\n",
        "\n",
        "Hay 5000 ejemplos de entrenamiento en `ex3data1.mat`, donde cada ejemplo de entrenamiento es una imagen en escala de grises de 20 píxeles por 20 píxeles del dígito. Cada píxel está representado por un número de punto flotante que indica la intensidad de la escala de grises en esa ubicación. La cuadrícula de 20 por 20 píxeles se \"desenrolla\" en un vector de 400 dimensiones. Cada uno de estos ejemplos de entrenamiento se convierte en una sola fila en nuestra matriz de datos \"X\". Esto da una matriz `X` de 5000 por 400 donde cada fila es un ejemplo de entrenamiento para una imagen de dígitos escrita a mano.\n",
        "\n",
        "$$ X = \\begin{bmatrix} - \\: (x^{(1)})^T \\: - \\\\ -\\: (x^{(2)})^T \\:- \\\\ \\vdots \\\\ - \\: (x^{(m)})^T \\:-  \\end{bmatrix} $$\n",
        "\n",
        "La segunda parte del conjunto de entrenamiento es un vector \"y\" de 5000 dimensiones que contiene etiquetas para el conjunto de entrenamiento. \n",
        "\n",
        "Se inicia el ejercicio cargando primero el conjunto de datos. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NyVlw5sValMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc7663b-b5c7-4d6d-d13d-01a5d1d13c3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Carga de dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/2 PARCIAL/datasets/dataset-tortuga.csv', header=0)"
      ],
      "metadata": {
        "id": "xjPrD0S6ewPH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRATAMIENTO DE DATOS**"
      ],
      "metadata": {
        "id": "AmIZyJn_ezly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "xHkUyZOtXkEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242a1d03-4999-41a6-da0a-7dae20ea7579"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0               NAME   USER_ID  HOURS_DATASCIENCE  \\\n",
            "0              28        Stormy Muto  58283940                7.0   \n",
            "1              81       Carlos Ferro   1357218               32.0   \n",
            "2              89  Robby Constantini  63212105               45.0   \n",
            "3             138       Paul Mckenny  23239851               36.0   \n",
            "4             143          Jean Webb  72234478               61.0   \n",
            "...           ...                ...       ...                ...   \n",
            "19995       20495        Rose Jurado  66754730                0.0   \n",
            "19996       20496       Johnny Jones   6874888                0.0   \n",
            "19997       20497    Lawrence Givens  83752787               32.0   \n",
            "19998       20498    Betty Diclaudio  45806698                0.0   \n",
            "19999       20499      Connie Harper  67068866               51.0   \n",
            "\n",
            "       HOURS_BACKEND  HOURS_FRONTEND  NUM_COURSES_BEGINNER_DATASCIENCE  \\\n",
            "0               39.0            29.0                               2.0   \n",
            "1                0.0            44.0                               2.0   \n",
            "2                0.0            59.0                               0.0   \n",
            "3               19.0            28.0                               0.0   \n",
            "4               78.0            38.0                               6.0   \n",
            "...              ...             ...                               ...   \n",
            "19995           44.0            42.0                               8.0   \n",
            "19996           85.0            63.0                               3.0   \n",
            "19997           50.0            22.0                               0.0   \n",
            "19998           96.0            69.0                               3.0   \n",
            "19999           24.0            36.0                               4.0   \n",
            "\n",
            "       NUM_COURSES_BEGINNER_BACKEND  NUM_COURSES_BEGINNER_FRONTEND  \\\n",
            "0                               4.0                            0.0   \n",
            "1                               0.0                            0.0   \n",
            "2                               5.0                            4.0   \n",
            "3                               5.0                            7.0   \n",
            "4                              11.0                            0.0   \n",
            "...                             ...                            ...   \n",
            "19995                           4.0                            7.0   \n",
            "19996                           5.0                            0.0   \n",
            "19997                           4.0                            0.0   \n",
            "19998                           3.0                            3.0   \n",
            "19999                           2.0                            7.0   \n",
            "\n",
            "       NUM_COURSES_ADVANCED_DATASCIENCE  NUM_COURSES_ADVANCED_BACKEND  \\\n",
            "0                                   2.0                           5.0   \n",
            "1                                   0.0                           5.0   \n",
            "2                                   0.0                           4.0   \n",
            "3                                   0.0                           5.0   \n",
            "4                                   4.0                           3.0   \n",
            "...                                 ...                           ...   \n",
            "19995                               3.0                           3.0   \n",
            "19996                               4.0                           7.0   \n",
            "19997                               6.0                           2.0   \n",
            "19998                               5.0                           7.0   \n",
            "19999                               0.0                           0.0   \n",
            "\n",
            "       NUM_COURSES_ADVANCED_FRONTEND  AVG_SCORE_DATASCIENCE  \\\n",
            "0                                0.0                   84.0   \n",
            "1                                0.0                   67.0   \n",
            "2                                1.0                    NaN   \n",
            "3                                3.0                    NaN   \n",
            "4                                0.0                   66.0   \n",
            "...                              ...                    ...   \n",
            "19995                            3.0                   74.0   \n",
            "19996                            3.0                   50.0   \n",
            "19997                            3.0                   61.0   \n",
            "19998                            4.0                   64.0   \n",
            "19999                            2.0                   63.0   \n",
            "\n",
            "       AVG_SCORE_BACKEND  AVG_SCORE_FRONTEND                PROFILE  \n",
            "0                   74.0                 NaN     beginner_front_end  \n",
            "1                   45.0                 NaN     beginner_front_end  \n",
            "2                   54.0                47.0     advanced_front_end  \n",
            "3                   71.0                89.0  beginner_data_science  \n",
            "4                   85.0                 NaN     advanced_front_end  \n",
            "...                  ...                 ...                    ...  \n",
            "19995               73.0                93.0       advanced_backend  \n",
            "19996               83.0                94.0     advanced_front_end  \n",
            "19997               81.0                75.0       advanced_backend  \n",
            "19998               68.0                68.0     advanced_front_end  \n",
            "19999               61.0                87.0  advanced_data_science  \n",
            "\n",
            "[20000 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "s2ZXYQ0gXoGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa41a1d3-6683-4fe7-a5c8-39a85eae48c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 16 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   Unnamed: 0                        20000 non-null  int64  \n",
            " 1   NAME                              20000 non-null  object \n",
            " 2   USER_ID                           20000 non-null  int64  \n",
            " 3   HOURS_DATASCIENCE                 19986 non-null  float64\n",
            " 4   HOURS_BACKEND                     19947 non-null  float64\n",
            " 5   HOURS_FRONTEND                    19984 non-null  float64\n",
            " 6   NUM_COURSES_BEGINNER_DATASCIENCE  19974 non-null  float64\n",
            " 7   NUM_COURSES_BEGINNER_BACKEND      19982 non-null  float64\n",
            " 8   NUM_COURSES_BEGINNER_FRONTEND     19961 non-null  float64\n",
            " 9   NUM_COURSES_ADVANCED_DATASCIENCE  19998 non-null  float64\n",
            " 10  NUM_COURSES_ADVANCED_BACKEND      19992 non-null  float64\n",
            " 11  NUM_COURSES_ADVANCED_FRONTEND     19963 non-null  float64\n",
            " 12  AVG_SCORE_DATASCIENCE             19780 non-null  float64\n",
            " 13  AVG_SCORE_BACKEND                 19916 non-null  float64\n",
            " 14  AVG_SCORE_FRONTEND                19832 non-null  float64\n",
            " 15  PROFILE                           20000 non-null  object \n",
            "dtypes: float64(12), int64(2), object(2)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyxQHr3KeRWN",
        "outputId": "a68fc92f-ed54-470f-fe4b-bdc8240364ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'NAME', 'USER_ID', 'HOURS_DATASCIENCE', 'HOURS_BACKEND',\n",
            "       'HOURS_FRONTEND', 'NUM_COURSES_BEGINNER_DATASCIENCE',\n",
            "       'NUM_COURSES_BEGINNER_BACKEND', 'NUM_COURSES_BEGINNER_FRONTEND',\n",
            "       'NUM_COURSES_ADVANCED_DATASCIENCE', 'NUM_COURSES_ADVANCED_BACKEND',\n",
            "       'NUM_COURSES_ADVANCED_FRONTEND', 'AVG_SCORE_DATASCIENCE',\n",
            "       'AVG_SCORE_BACKEND', 'AVG_SCORE_FRONTEND', 'PROFILE'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminar una columna\n",
        "columnas_eiliminar = ['Unnamed: 0', 'USER_ID', 'NAME']\n",
        "data = data.drop(columnas_eiliminar, axis=1)"
      ],
      "metadata": {
        "id": "3f0l0gTFYO-w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtsaSh8bevxP",
        "outputId": "4151093a-ee8c-4238-a55b-1c232430bfbd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 13 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   HOURS_DATASCIENCE                 19986 non-null  float64\n",
            " 1   HOURS_BACKEND                     19947 non-null  float64\n",
            " 2   HOURS_FRONTEND                    19984 non-null  float64\n",
            " 3   NUM_COURSES_BEGINNER_DATASCIENCE  19974 non-null  float64\n",
            " 4   NUM_COURSES_BEGINNER_BACKEND      19982 non-null  float64\n",
            " 5   NUM_COURSES_BEGINNER_FRONTEND     19961 non-null  float64\n",
            " 6   NUM_COURSES_ADVANCED_DATASCIENCE  19998 non-null  float64\n",
            " 7   NUM_COURSES_ADVANCED_BACKEND      19992 non-null  float64\n",
            " 8   NUM_COURSES_ADVANCED_FRONTEND     19963 non-null  float64\n",
            " 9   AVG_SCORE_DATASCIENCE             19780 non-null  float64\n",
            " 10  AVG_SCORE_BACKEND                 19916 non-null  float64\n",
            " 11  AVG_SCORE_FRONTEND                19832 non-null  float64\n",
            " 12  PROFILE                           20000 non-null  object \n",
            "dtypes: float64(12), object(1)\n",
            "memory usage: 2.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_categoricas = data.select_dtypes(include=['object']).columns\n",
        "#columnas_fechas = data.select_dtypes(include=['datetime64']).columns"
      ],
      "metadata": {
        "id": "-drjsXblXpuW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7EdLE3jfSJv",
        "outputId": "12a7a6bb-f8c1-43db-800a-95a512275c31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 13 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   HOURS_DATASCIENCE                 19986 non-null  float64\n",
            " 1   HOURS_BACKEND                     19947 non-null  float64\n",
            " 2   HOURS_FRONTEND                    19984 non-null  float64\n",
            " 3   NUM_COURSES_BEGINNER_DATASCIENCE  19974 non-null  float64\n",
            " 4   NUM_COURSES_BEGINNER_BACKEND      19982 non-null  float64\n",
            " 5   NUM_COURSES_BEGINNER_FRONTEND     19961 non-null  float64\n",
            " 6   NUM_COURSES_ADVANCED_DATASCIENCE  19998 non-null  float64\n",
            " 7   NUM_COURSES_ADVANCED_BACKEND      19992 non-null  float64\n",
            " 8   NUM_COURSES_ADVANCED_FRONTEND     19963 non-null  float64\n",
            " 9   AVG_SCORE_DATASCIENCE             19780 non-null  float64\n",
            " 10  AVG_SCORE_BACKEND                 19916 non-null  float64\n",
            " 11  AVG_SCORE_FRONTEND                19832 non-null  float64\n",
            " 12  PROFILE                           20000 non-null  object \n",
            "dtypes: float64(12), object(1)\n",
            "memory usage: 2.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG9SGYXvfr74",
        "outputId": "084a21c7-6279-4cad-c812-058de2667636"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['HOURS_DATASCIENCE', 'HOURS_BACKEND', 'HOURS_FRONTEND',\n",
            "       'NUM_COURSES_BEGINNER_DATASCIENCE', 'NUM_COURSES_BEGINNER_BACKEND',\n",
            "       'NUM_COURSES_BEGINNER_FRONTEND', 'NUM_COURSES_ADVANCED_DATASCIENCE',\n",
            "       'NUM_COURSES_ADVANCED_BACKEND', 'NUM_COURSES_ADVANCED_FRONTEND',\n",
            "       'AVG_SCORE_DATASCIENCE', 'AVG_SCORE_BACKEND', 'AVG_SCORE_FRONTEND',\n",
            "       'PROFILE'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Procesamiento de frases\n",
        "for columna in columnas_categoricas:\n",
        "  le = LabelEncoder()\n",
        "  data[columna] = le.fit_transform(data[columna])"
      ],
      "metadata": {
        "id": "qO5AcEJjYAvY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Fechas a numeros\n",
        "# for columna in columnas_fechas:\n",
        "#   data[columna] = pd.to_numeric(data[columna].map(datetime.timestamp))"
      ],
      "metadata": {
        "id": "gMjTay2dYCOJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#llenar datos vacios\n",
        "columnas_especificas = ['HOURS_DATASCIENCE', 'HOURS_BACKEND', 'HOURS_FRONTEND', 'NUM_COURSES_BEGINNER_DATASCIENCE',  'NUM_COURSES_BEGINNER_BACKEND', \n",
        "                        'NUM_COURSES_BEGINNER_FRONTEND', 'NUM_COURSES_ADVANCED_DATASCIENCE', 'NUM_COURSES_ADVANCED_BACKEND', 'NUM_COURSES_ADVANCED_FRONTEND', \n",
        "                        'AVG_SCORE_DATASCIENCE','AVG_SCORE_BACKEND', 'AVG_SCORE_FRONTEND'  ]\n",
        "media_columnas = data[columnas_especificas].mean()\n",
        "data[columnas_especificas] = data[columnas_especificas].fillna(media_columnas)"
      ],
      "metadata": {
        "id": "wjQVSDrDYHpy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JHkDkRJhMbQ",
        "outputId": "7151388b-4220-468f-d9f2-95316be9204d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 13 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   HOURS_DATASCIENCE                 20000 non-null  float64\n",
            " 1   HOURS_BACKEND                     20000 non-null  float64\n",
            " 2   HOURS_FRONTEND                    20000 non-null  float64\n",
            " 3   NUM_COURSES_BEGINNER_DATASCIENCE  20000 non-null  float64\n",
            " 4   NUM_COURSES_BEGINNER_BACKEND      20000 non-null  float64\n",
            " 5   NUM_COURSES_BEGINNER_FRONTEND     20000 non-null  float64\n",
            " 6   NUM_COURSES_ADVANCED_DATASCIENCE  20000 non-null  float64\n",
            " 7   NUM_COURSES_ADVANCED_BACKEND      20000 non-null  float64\n",
            " 8   NUM_COURSES_ADVANCED_FRONTEND     20000 non-null  float64\n",
            " 9   AVG_SCORE_DATASCIENCE             20000 non-null  float64\n",
            " 10  AVG_SCORE_BACKEND                 20000 non-null  float64\n",
            " 11  AVG_SCORE_FRONTEND                20000 non-null  float64\n",
            " 12  PROFILE                           20000 non-null  int64  \n",
            "dtypes: float64(12), int64(1)\n",
            "memory usage: 2.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ASIGNAR VARIABLE X y Y**"
      ],
      "metadata": {
        "id": "nvHuuGC0fUaw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IIo4_PncaSAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be86028-aed5-4ea8-939c-87cef51a7280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-7c0152e62377>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y[y == 10] = 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 10 etiquetas, de 1 a 10 (tomar en cuenta que se asigna \"0\" a la etiqueta 10)\n",
        "num_labels = 6\n",
        "\n",
        "#  datos de entrenamiento almacenados en los arreglos X, y\n",
        "#data = loadmat(os.path.join('/content/drive/MyDrive/Machine Learning/Datasets/ex3data1.mat'))\n",
        "#X, y = data['X'], data['y'].ravel()\n",
        "\n",
        "X = data.iloc[:, 0:12]\n",
        "y = data.iloc[: ,12]\n",
        "\n",
        "# establecer el dígito cero en 0, en lugar del 10 asignado a este conjunto de datos\n",
        "# Esto se hace debido a que el conjunto de datos se utilizó en MATLAB donde no hay índice 0\n",
        "y[y == 10] = 0\n",
        "\n",
        "m = y.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx2OiWpnaSAf",
        "outputId": "ee42fe19-f63c-4e3e-c394-e7dab451e1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       HOURS_DATASCIENCE  HOURS_BACKEND  HOURS_FRONTEND  \\\n",
            "0                    7.0           39.0            29.0   \n",
            "1                   32.0            0.0            44.0   \n",
            "2                   45.0            0.0            59.0   \n",
            "3                   36.0           19.0            28.0   \n",
            "4                   61.0           78.0            38.0   \n",
            "...                  ...            ...             ...   \n",
            "19995                0.0           44.0            42.0   \n",
            "19996                0.0           85.0            63.0   \n",
            "19997               32.0           50.0            22.0   \n",
            "19998                0.0           96.0            69.0   \n",
            "19999               51.0           24.0            36.0   \n",
            "\n",
            "       NUM_COURSES_BEGINNER_DATASCIENCE  NUM_COURSES_BEGINNER_BACKEND  \\\n",
            "0                                   2.0                           4.0   \n",
            "1                                   2.0                           0.0   \n",
            "2                                   0.0                           5.0   \n",
            "3                                   0.0                           5.0   \n",
            "4                                   6.0                          11.0   \n",
            "...                                 ...                           ...   \n",
            "19995                               8.0                           4.0   \n",
            "19996                               3.0                           5.0   \n",
            "19997                               0.0                           4.0   \n",
            "19998                               3.0                           3.0   \n",
            "19999                               4.0                           2.0   \n",
            "\n",
            "       NUM_COURSES_BEGINNER_FRONTEND  NUM_COURSES_ADVANCED_DATASCIENCE  \\\n",
            "0                                0.0                               2.0   \n",
            "1                                0.0                               0.0   \n",
            "2                                4.0                               0.0   \n",
            "3                                7.0                               0.0   \n",
            "4                                0.0                               4.0   \n",
            "...                              ...                               ...   \n",
            "19995                            7.0                               3.0   \n",
            "19996                            0.0                               4.0   \n",
            "19997                            0.0                               6.0   \n",
            "19998                            3.0                               5.0   \n",
            "19999                            7.0                               0.0   \n",
            "\n",
            "       NUM_COURSES_ADVANCED_BACKEND  NUM_COURSES_ADVANCED_FRONTEND  \\\n",
            "0                               5.0                            0.0   \n",
            "1                               5.0                            0.0   \n",
            "2                               4.0                            1.0   \n",
            "3                               5.0                            3.0   \n",
            "4                               3.0                            0.0   \n",
            "...                             ...                            ...   \n",
            "19995                           3.0                            3.0   \n",
            "19996                           7.0                            3.0   \n",
            "19997                           2.0                            3.0   \n",
            "19998                           7.0                            4.0   \n",
            "19999                           0.0                            2.0   \n",
            "\n",
            "       AVG_SCORE_DATASCIENCE  AVG_SCORE_BACKEND  AVG_SCORE_FRONTEND  \n",
            "0                  84.000000               74.0           67.130748  \n",
            "1                  67.000000               45.0           67.130748  \n",
            "2                  65.070324               54.0           47.000000  \n",
            "3                  65.070324               71.0           89.000000  \n",
            "4                  66.000000               85.0           67.130748  \n",
            "...                      ...                ...                 ...  \n",
            "19995              74.000000               73.0           93.000000  \n",
            "19996              50.000000               83.0           94.000000  \n",
            "19997              61.000000               81.0           75.000000  \n",
            "19998              64.000000               68.0           68.000000  \n",
            "19999              63.000000               61.0           87.000000  \n",
            "\n",
            "[20000 rows x 12 columns]\n",
            "*********************\n",
            "0        5\n",
            "1        5\n",
            "2        2\n",
            "3        4\n",
            "4        2\n",
            "        ..\n",
            "19995    0\n",
            "19996    2\n",
            "19997    0\n",
            "19998    2\n",
            "19999    1\n",
            "Name: PROFILE, Length: 20000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(X)\n",
        "print('*'*21)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FUNCION DE NORMALIZACION DE DATOS**"
      ],
      "metadata": {
        "id": "Ajsw6Di2f0A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  featureNormalize(X):\n",
        "    X_norm = X.copy()\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "    X_norm = (X - mu) / sigma\n",
        "    \n",
        "    return X_norm, mu, sigma"
      ],
      "metadata": {
        "id": "sQV5La9Zf353"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#llama featureNormalize con los datos cargados\n",
        "X_norm, mu, sigma = featureNormalize(X)\n",
        "\n",
        "print(X)\n",
        "print('Media calculada:', mu)\n",
        "print('Desviación estandar calculada:', sigma)\n",
        "print(X_norm)"
      ],
      "metadata": {
        "id": "vLHHKLAIf5NG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30420cd7-cabf-4c6a-d918-94ede9e771fd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       HOURS_DATASCIENCE  HOURS_BACKEND  HOURS_FRONTEND  \\\n",
            "0                    7.0           39.0            29.0   \n",
            "1                   32.0            0.0            44.0   \n",
            "2                   45.0            0.0            59.0   \n",
            "3                   36.0           19.0            28.0   \n",
            "4                   61.0           78.0            38.0   \n",
            "...                  ...            ...             ...   \n",
            "19995                0.0           44.0            42.0   \n",
            "19996                0.0           85.0            63.0   \n",
            "19997               32.0           50.0            22.0   \n",
            "19998                0.0           96.0            69.0   \n",
            "19999               51.0           24.0            36.0   \n",
            "\n",
            "       NUM_COURSES_BEGINNER_DATASCIENCE  NUM_COURSES_BEGINNER_BACKEND  \\\n",
            "0                                   2.0                           4.0   \n",
            "1                                   2.0                           0.0   \n",
            "2                                   0.0                           5.0   \n",
            "3                                   0.0                           5.0   \n",
            "4                                   6.0                          11.0   \n",
            "...                                 ...                           ...   \n",
            "19995                               8.0                           4.0   \n",
            "19996                               3.0                           5.0   \n",
            "19997                               0.0                           4.0   \n",
            "19998                               3.0                           3.0   \n",
            "19999                               4.0                           2.0   \n",
            "\n",
            "       NUM_COURSES_BEGINNER_FRONTEND  NUM_COURSES_ADVANCED_DATASCIENCE  \\\n",
            "0                                0.0                               2.0   \n",
            "1                                0.0                               0.0   \n",
            "2                                4.0                               0.0   \n",
            "3                                7.0                               0.0   \n",
            "4                                0.0                               4.0   \n",
            "...                              ...                               ...   \n",
            "19995                            7.0                               3.0   \n",
            "19996                            0.0                               4.0   \n",
            "19997                            0.0                               6.0   \n",
            "19998                            3.0                               5.0   \n",
            "19999                            7.0                               0.0   \n",
            "\n",
            "       NUM_COURSES_ADVANCED_BACKEND  NUM_COURSES_ADVANCED_FRONTEND  \\\n",
            "0                               5.0                            0.0   \n",
            "1                               5.0                            0.0   \n",
            "2                               4.0                            1.0   \n",
            "3                               5.0                            3.0   \n",
            "4                               3.0                            0.0   \n",
            "...                             ...                            ...   \n",
            "19995                           3.0                            3.0   \n",
            "19996                           7.0                            3.0   \n",
            "19997                           2.0                            3.0   \n",
            "19998                           7.0                            4.0   \n",
            "19999                           0.0                            2.0   \n",
            "\n",
            "       AVG_SCORE_DATASCIENCE  AVG_SCORE_BACKEND  AVG_SCORE_FRONTEND  \n",
            "0                  84.000000               74.0           67.130748  \n",
            "1                  67.000000               45.0           67.130748  \n",
            "2                  65.070324               54.0           47.000000  \n",
            "3                  65.070324               71.0           89.000000  \n",
            "4                  66.000000               85.0           67.130748  \n",
            "...                      ...                ...                 ...  \n",
            "19995              74.000000               73.0           93.000000  \n",
            "19996              50.000000               83.0           94.000000  \n",
            "19997              61.000000               81.0           75.000000  \n",
            "19998              64.000000               68.0           68.000000  \n",
            "19999              63.000000               61.0           87.000000  \n",
            "\n",
            "[20000 rows x 12 columns]\n",
            "Media calculada: HOURS_DATASCIENCE                   37.565296\n",
            "HOURS_BACKEND                       43.552263\n",
            "HOURS_FRONTEND                      36.936599\n",
            "NUM_COURSES_BEGINNER_DATASCIENCE     3.698608\n",
            "NUM_COURSES_BEGINNER_BACKEND         3.715144\n",
            "NUM_COURSES_BEGINNER_FRONTEND        4.048294\n",
            "NUM_COURSES_ADVANCED_DATASCIENCE     3.397140\n",
            "NUM_COURSES_ADVANCED_BACKEND         4.344338\n",
            "NUM_COURSES_ADVANCED_FRONTEND        3.367830\n",
            "AVG_SCORE_DATASCIENCE               65.070324\n",
            "AVG_SCORE_BACKEND                   67.234535\n",
            "AVG_SCORE_FRONTEND                  67.130748\n",
            "dtype: float64\n",
            "Desviación estandar calculada: HOURS_DATASCIENCE                   22.386406\n",
            "HOURS_BACKEND                       22.357274\n",
            "HOURS_FRONTEND                      20.581629\n",
            "NUM_COURSES_BEGINNER_DATASCIENCE     2.000295\n",
            "NUM_COURSES_BEGINNER_BACKEND         2.100864\n",
            "NUM_COURSES_BEGINNER_FRONTEND        2.293703\n",
            "NUM_COURSES_ADVANCED_DATASCIENCE     2.111278\n",
            "NUM_COURSES_ADVANCED_BACKEND         2.161083\n",
            "NUM_COURSES_ADVANCED_FRONTEND        1.985951\n",
            "AVG_SCORE_DATASCIENCE               13.873268\n",
            "AVG_SCORE_BACKEND                   14.184353\n",
            "AVG_SCORE_FRONTEND                  14.385663\n",
            "dtype: float64\n",
            "       HOURS_DATASCIENCE  HOURS_BACKEND  HOURS_FRONTEND  \\\n",
            "0              -1.365351      -0.203614       -0.385616   \n",
            "1              -0.248602      -1.948013        0.343190   \n",
            "2               0.332108      -1.948013        1.071995   \n",
            "3              -0.069922      -1.098178       -0.434203   \n",
            "4               1.046827       1.540784        0.051667   \n",
            "...                  ...            ...             ...   \n",
            "19995          -1.678041       0.020026        0.246016   \n",
            "19996          -1.678041       1.853881        1.266343   \n",
            "19997          -0.248602       0.288395       -0.725725   \n",
            "19998          -1.678041       2.345891        1.557865   \n",
            "19999           0.600128      -0.874537       -0.045507   \n",
            "\n",
            "       NUM_COURSES_BEGINNER_DATASCIENCE  NUM_COURSES_BEGINNER_BACKEND  \\\n",
            "0                             -0.849179                      0.135590   \n",
            "1                             -0.849179                     -1.768388   \n",
            "2                             -1.849031                      0.611585   \n",
            "3                             -1.849031                      0.611585   \n",
            "4                              1.150526                      3.467552   \n",
            "...                                 ...                           ...   \n",
            "19995                          2.150378                      0.135590   \n",
            "19996                         -0.349253                      0.611585   \n",
            "19997                         -1.849031                      0.135590   \n",
            "19998                         -0.349253                     -0.340405   \n",
            "19999                          0.150674                     -0.816399   \n",
            "\n",
            "       NUM_COURSES_BEGINNER_FRONTEND  NUM_COURSES_ADVANCED_DATASCIENCE  \\\n",
            "0                          -1.764960                         -0.661751   \n",
            "1                          -1.764960                         -1.609044   \n",
            "2                          -0.021055                         -1.609044   \n",
            "3                           1.286874                         -1.609044   \n",
            "4                          -1.764960                          0.285543   \n",
            "...                              ...                               ...   \n",
            "19995                       1.286874                         -0.188104   \n",
            "19996                      -1.764960                          0.285543   \n",
            "19997                      -1.764960                          1.232836   \n",
            "19998                      -0.457031                          0.759190   \n",
            "19999                       1.286874                         -1.609044   \n",
            "\n",
            "       NUM_COURSES_ADVANCED_BACKEND  NUM_COURSES_ADVANCED_FRONTEND  \\\n",
            "0                          0.303395                      -1.695828   \n",
            "1                          0.303395                      -1.695828   \n",
            "2                         -0.159336                      -1.192291   \n",
            "3                          0.303395                      -0.185216   \n",
            "4                         -0.622067                      -1.695828   \n",
            "...                             ...                            ...   \n",
            "19995                     -0.622067                      -0.185216   \n",
            "19996                      1.228857                      -0.185216   \n",
            "19997                     -1.084798                      -0.185216   \n",
            "19998                      1.228857                       0.318321   \n",
            "19999                     -2.010260                      -0.688753   \n",
            "\n",
            "       AVG_SCORE_DATASCIENCE  AVG_SCORE_BACKEND  AVG_SCORE_FRONTEND  \n",
            "0                   1.364471           0.476967            0.000000  \n",
            "1                   0.139093          -1.567540            0.000000  \n",
            "2                   0.000000          -0.933038           -1.399362  \n",
            "3                   0.000000           0.265466            1.520212  \n",
            "4                   0.067012           1.252469            0.000000  \n",
            "...                      ...                ...                 ...  \n",
            "19995               0.643661           0.406467            1.798266  \n",
            "19996              -1.086285           1.111469            1.867780  \n",
            "19997              -0.293393           0.970468            0.547020  \n",
            "19998              -0.077150           0.053965            0.060425  \n",
            "19999              -0.149231          -0.439536            1.381184  \n",
            "\n",
            "[20000 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Añade el termino de interseccion a X\n",
        "# (Columna de unos para X0)\n",
        "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
      ],
      "metadata": {
        "id": "XYGA16ZRf7dF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X[1])"
      ],
      "metadata": {
        "id": "urpkecrsf9gd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sik3dkCKoT3g",
        "outputId": "c04e401b-128c-4d02-82f3-59c32aa2dd38"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.         -1.36535074 -0.20361442 ...  1.36447135  0.47696676\n",
            "   0.        ]\n",
            " [ 1.         -0.24860157 -1.94801311 ...  0.13909314 -1.56753958\n",
            "   0.        ]\n",
            " [ 1.          0.33210799 -1.94801311 ...  0.         -0.93303762\n",
            "  -1.39936188]\n",
            " ...\n",
            " [ 1.         -0.24860157  0.28839546 ... -0.29339328  0.97046829\n",
            "   0.54702044]\n",
            " [ 1.         -1.67804051  2.34589136 ... -0.07715007  0.05396545\n",
            "   0.06042486]\n",
            " [ 1.          0.60012779 -0.874537   ... -0.14923114 -0.43953608\n",
            "   1.38118429]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "mKiIB3l1aSAh"
      },
      "source": [
        "### 1.3 Vectorización de regresión logística\n",
        "\n",
        "Se utilizará múltiples modelos de regresión logística uno contra todos para construir un clasificador de clases múltiples. Dado que hay 10 clases, deberá entrenar 10 clasificadores de regresión logística separados. Para que esta capacitación sea eficiente, es importante asegurarse de que el código esté bien vectorizado.\n",
        "\n",
        "En esta sección, se implementará una versión vectorizada de regresión logística que no emplea ningún bucle \"for\".\n",
        "\n",
        "Para probar la regresión logística vectorizada, se usara datos personalizados como se definen a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "A9A3w9XcaSAi"
      },
      "outputs": [],
      "source": [
        "# valores de prueba para los parámetros theta\n",
        "theta_t = np.array([-2, -1, 1, 2], dtype=float)\n",
        "\n",
        "# valores de prueba para las entradas\n",
        "X_t = np.concatenate([np.ones((5, 1)), np.arange(1, 16).reshape(5, 3, order='F')/10.0], axis=1)\n",
        "\n",
        "# valores de testeo para las etiquetas\n",
        "y_t = np.array([1, 0, 1, 0, 1])\n",
        "\n",
        "# valores de testeo para el parametro de regularizacion\n",
        "lambda_t = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0B7RynzaSAi"
      },
      "source": [
        "<a id=\"section1\"></a>\n",
        "#### 1.3.1 Vectorización de la funcion de costo\n",
        "\n",
        "Se inicia escribiendo una versión vectorizada de la función de costo. En la regresión logística (no regularizada), la función de costo es\n",
        "\n",
        "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y^{(i)} \\log \\left( h_\\theta\\left( x^{(i)} \\right) \\right) - \\left(1 - y^{(i)} \\right) \\log \\left(1 - h_\\theta \\left( x^{(i)} \\right) \\right) \\right] $$\n",
        "\n",
        "Para calcular cada elemento en la suma, tenemos que calcular $h_\\theta(x^{(i)})$ para cada ejemplo $i$, donde $h_\\theta(x^{(i)}) = g(\\theta^T x^{(i)})$ y $g(z) = \\frac{1}{1+e^{-z}}$ es la funcion sigmoidea. Resulta que podemos calcular esto rápidamente para todos los ejemplos usando la multiplicación de matrices. Definamos $X$ y $\\theta$ como\n",
        "\n",
        "$$ X = \\begin{bmatrix} - \\left( x^{(1)} \\right)^T - \\\\ - \\left( x^{(2)} \\right)^T - \\\\ \\vdots \\\\ - \\left( x^{(m)} \\right)^T - \\end{bmatrix} \\qquad \\text{and} \\qquad \\theta = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\vdots \\\\ \\theta_n \\end{bmatrix} $$\n",
        "\n",
        "Luego, de calcular el producto matricial $X\\theta$, se tiene: \n",
        "\n",
        "$$ X\\theta = \\begin{bmatrix} - \\left( x^{(1)} \\right)^T\\theta - \\\\ - \\left( x^{(2)} \\right)^T\\theta - \\\\ \\vdots \\\\ - \\left( x^{(m)} \\right)^T\\theta - \\end{bmatrix} = \\begin{bmatrix} - \\theta^T x^{(1)}  - \\\\ - \\theta^T x^{(2)} - \\\\ \\vdots \\\\ - \\theta^T x^{(m)}  - \\end{bmatrix} $$\n",
        "\n",
        "En la última igualdad, usamos el hecho de que $a^Tb = b^Ta$ if $a$ y $b$ son vectores. Esto permite calcular los productos $\\theta^T x^{(i)}$ para todos los ejemplos $i$ en una linea de codigo.\n",
        "\n",
        "#### 1.3.2 Vectorización del gradiente\n",
        "\n",
        "Recordemos que el gradiente del costo de regresión logística (no regularizado) es un vector donde el elemento $j^{th}$ se define como\n",
        "$$ \\frac{\\partial J }{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( \\left( h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_j^{(i)} \\right) $$\n",
        "\n",
        "Para vectorizar esta operación sobre el conjunto de datos, se inicia escribiendo todas las derivadas parciales explícitamente para todos $\\theta_j$,\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix} \n",
        "\\frac{\\partial J}{\\partial \\theta_0} \\\\\n",
        "\\frac{\\partial J}{\\partial \\theta_1} \\\\\n",
        "\\frac{\\partial J}{\\partial \\theta_2} \\\\\n",
        "\\vdots \\\\\n",
        "\\frac{\\partial J}{\\partial \\theta_n}\n",
        "\\end{bmatrix} = &\n",
        "\\frac{1}{m} \\begin{bmatrix}\n",
        "\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_0^{(i)}\\right) \\\\\n",
        "\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_1^{(i)}\\right) \\\\\n",
        "\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_2^{(i)}\\right) \\\\\n",
        "\\vdots \\\\\n",
        "\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_n^{(i)}\\right) \\\\\n",
        "\\end{bmatrix} \\\\\n",
        "= & \\frac{1}{m} \\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x^{(i)}\\right) \\\\\n",
        "= & \\frac{1}{m} X^T \\left( h_\\theta(x) - y\\right)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "donde\n",
        "\n",
        "$$  h_\\theta(x) - y = \n",
        "\\begin{bmatrix}\n",
        "h_\\theta\\left(x^{(1)}\\right) - y^{(1)} \\\\\n",
        "h_\\theta\\left(x^{(2)}\\right) - y^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "h_\\theta\\left(x^{(m)}\\right) - y^{(m)} \n",
        "\\end{bmatrix} $$\n",
        "\n",
        "Nota $x^{(i)}$ es un vector, mientras $h_\\theta\\left(x^{(i)}\\right) - y^{(i)}$ es un escalar(simple número).\n",
        "Para comprender el último paso de la derivación, dejemos $\\beta_i = (h_\\theta\\left(x^{(m)}\\right) - y^{(m)})$ y\n",
        "observar que:\n",
        "\n",
        "$$ \\sum_i \\beta_ix^{(i)} = \\begin{bmatrix} \n",
        "| & | & & | \\\\\n",
        "x^{(1)} & x^{(2)} & \\cdots & x^{(m)} \\\\\n",
        "| & | & & | \n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "\\beta_1 \\\\\n",
        "\\beta_2 \\\\\n",
        "\\vdots \\\\\n",
        "\\beta_m\n",
        "\\end{bmatrix} = x^T \\beta\n",
        "$$\n",
        "\n",
        "donde los valores $\\beta_i = \\left( h_\\theta(x^{(i)} - y^{(i)} \\right)$.\n",
        "\n",
        "La expresión anterior nos permite calcular todas las derivadas parciales sin bucles.\n",
        "Si se siente cómodo con el álgebra lineal, le recomendamos que trabaje con las multiplicaciones de matrices anteriores para convencerse de que la versión vectorizada hace los mismos cálculos.\n",
        "\n",
        "<div class=\"alert alert-box alert-warning\">\n",
        "** Consejo de depuración: ** El código de vectorización a veces puede ser complicado. Una estrategia común para la depuración es imprimir los tamaños de las matrices con las que está trabajando usando la propiedad `shape` de las matrices` numpy`.\n",
        "\n",
        "Por ejemplo, dada una matriz de datos $X$ de tamaño $100\\veces 20$ (100 ejemplos, 20 características) y $\\theta$, un vector con tamaño $20$, puede observar que `np.dot (X, theta) `es una operación de multiplicación válida, mientras que` np.dot (theta, X) `no lo es.\n",
        "\n",
        "Además, si tiene una versión no vectorizada de su código, puede comparar la salida de su código vectorizado y el código no vectorizado para asegurarse de que produzcan las mismas salidas.</div>\n",
        "<a id=\"lrCostFunction\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nTs3E6c2aSAi"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Calcula la sigmoide de z.\n",
        "    \"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "35J37PLpaSAj"
      },
      "outputs": [],
      "source": [
        "def lrCostFunction(theta, X, y, lambda_):\n",
        "    \"\"\"\n",
        "    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y \n",
        "    el gradiente del costo w.r.t. a los parámetros.\n",
        "    \n",
        "    Parametros\n",
        "    ----------\n",
        "    theta : array_like\n",
        "        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas \n",
        "        incluida la intercepcion\n",
        "        \n",
        "    X : array_like\n",
        "        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de \n",
        "        caracteristicas (incluida la intercepcion).\n",
        "    \n",
        "    y : array_like\n",
        "        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n",
        "    \n",
        "    lambda_ : float\n",
        "        Parametro de regularización. \n",
        "    \n",
        "    Devuelve\n",
        "    -------\n",
        "    J : float\n",
        "        El valor calculado para la funcion de costo regularizada. \n",
        "    \n",
        "    grad : array_like\n",
        "        Un vector de la forma (shape) (n, ) que es el gradiente de la \n",
        "        función de costo con respecto a theta, en los valores actuales de theta..\n",
        "    \"\"\"\n",
        "    # Inicializa algunos valores utiles\n",
        "    m = y.size\n",
        "    \n",
        "    # convierte las etiquetas a valores enteros si son boleanos\n",
        "    if y.dtype == bool:\n",
        "        y = y.astype(int)\n",
        "    \n",
        "    J = 0\n",
        "    grad = np.zeros(theta.shape)\n",
        "    \n",
        "    h = sigmoid(X.dot(theta.T))\n",
        "    \n",
        "    temp = theta\n",
        "    temp[0] = 0\n",
        "    \n",
        "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
        "    \n",
        "    grad = (1 / m) * (h - y).dot(X) \n",
        "    grad = grad + (lambda_ / m) * temp\n",
        "\n",
        "    return J, grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqmRn9AfaSAj"
      },
      "source": [
        "#### 1.3.3 Vectorización regularizada de la regresión logística\n",
        "\n",
        "Una vez implementada la vectorización para la regresión logística, corresponde agregarar regularización a la función de costo.\n",
        "Para la regresión logística regularizada, la función de costo se define como\n",
        "\n",
        "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y^{(i)} \\log \\left(h_\\theta\\left(x^{(i)} \\right)\\right) - \\left( 1 - y^{(i)} \\right) \\log\\left(1 - h_\\theta \\left(x^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j^2 $$\n",
        "\n",
        "Tomar en cuenta que no debería regularizarse $\\theta_0$ que se usa para el término de sesgo. En consecuencia, la derivada parcial del costo de regresión logística regularizado para $\\theta_j$ se define como\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "& \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)}  & \\text{for } j = 0 \\\\\n",
        "& \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\left( \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} \\right) + \\frac{\\lambda}{m} \\theta_j & \\text{for } j  \\ge 1\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "<div class=\"alert alert-box alert-warning\">\n",
        "** Python/numpy Consejo: ** Al implementar la vectorización para la regresión logística regularizada, a menudo es posible que solo desee sumar y actualizar ciertos elementos de $\\theta$. En `numpy`, puede indexar en las matrices para acceder y actualizar solo ciertos elementos.\n",
        "\n",
        "Por ejemplo, A [:, 3: 5] = B [:, 1: 3] reemplazará las columnas con índice 3 a 5 de A con las columnas con índice 1 a 3 de B.   \n",
        "Para seleccionar columnas (o filas) hasta el final de la matriz, puede dejar el lado derecho de los dos puntos en blanco.\n",
        "Por ejemplo, A [:, 2:] solo devolverá elementos desde $3^{rd}$ a las últimas columnas de $A$.Si deja el tamaño de la mano izquierda de los dos puntos en blanco, seleccionará los elementos del principio de la matriz.\n",
        "Por ejemplo, A [:,: 2] selecciona las dos primeras columnas y es equivalente a A [:, 0: 2]. Además, puede utilizar índices negativos para indexar matrices desde el final.\n",
        "Por lo tanto, A [:,: -1] selecciona todas las columnas de A excepto la última columna, y A [:, -5:] selecciona la columna $5^{th}$ desde el final hasta la última columna.\n",
        "\n",
        "Por lo tanto, podría usar esto junto con las operaciones de suma y potencia ($^{**}$) para calcular la suma de solo los elementos que le interesan (por ejemplo, `np.sum (z[1:]**2)`).\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl1B88pFaSAk",
        "outputId": "aaf1620f-97db-4b29-98e6-dc6bd6ed64d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Costo         : 2.534819\n",
            "Costo esperadot: 2.534819\n",
            "-----------------------\n",
            "Gradientes:\n",
            " [0.146561, -0.548558, 0.724722, 1.398003]\n",
            "Gradientes esperados:\n",
            " [0.146561, -0.548558, 0.724722, 1.398003]\n"
          ]
        }
      ],
      "source": [
        "J, grad = lrCostFunction(theta_t, X_t, y_t, lambda_t)\n",
        "\n",
        "print('Costo         : {:.6f}'.format(J))\n",
        "print('Costo esperadot: 2.534819')\n",
        "print('-----------------------')\n",
        "print('Gradientes:')\n",
        "print(' [{:.6f}, {:.6f}, {:.6f}, {:.6f}]'.format(*grad))\n",
        "print('Gradientes esperados:')\n",
        "print(' [0.146561, -0.548558, 0.724722, 1.398003]');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUcexElVaSAk"
      },
      "source": [
        "<a id=\"section2\"></a>\n",
        "### 1.4 Clasificacion One-vs-all\n",
        "En esta parte del ejercicio, se implementará la clasificación de uno contra todos mediante el entrenamiento de múltiples clasificadores de regresión logística regularizados, uno para cada una de las clases $K$ en nuestro conjunto de datos. En el conjunto de datos de dígitos escritos a mano, $K = 10$, pero su código debería funcionar para cualquier valor de $K$.\n",
        "\n",
        "El argumento `y` de esta función es un vector de etiquetas de 0 a 9. Al entrenar el clasificador para la clase $k \\in \\{0, ..., K-1 \\} $, querrá un vector K-dimensional de etiquetas $y$, donde $y_j \\ in 0, 1$ indica si la instancia de entrenamiento $j ^ {th}$ pertenece a la clase $k$ $(y_j = 1)$, o si pertenece a una clase diferente $(y_j = 0)$.\n",
        "\n",
        "Además, se utiliza `optimize.minimize` de scipy para este ejercicio.\n",
        "<a id=\"oneVsAll\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kwWxA1LgaSAk"
      },
      "outputs": [],
      "source": [
        "def oneVsAll(X, y, num_labels, lambda_):\n",
        "    \"\"\"\n",
        "    Trains num_labels logistic regression classifiers and returns\n",
        "    each of these classifiers in a matrix all_theta, where the i-th\n",
        "    row of all_theta corresponds to the classifier for label i.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array_like\n",
        "        The input dataset of shape (m x n). m is the number of \n",
        "        data points, and n is the number of features. Note that we \n",
        "        do not assume that the intercept term (or bias) is in X, however\n",
        "        we provide the code below to add the bias term to X. \n",
        "    \n",
        "    y : array_like\n",
        "        The data labels. A vector of shape (m, ).\n",
        "    \n",
        "    num_labels : int\n",
        "        Number of possible labels.\n",
        "    \n",
        "    lambda_ : float\n",
        "        The logistic regularization parameter.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        (ie. `numlabels`) and n is number of features without the bias.\n",
        "    \"\"\"\n",
        "    # algunas variables utiles\n",
        "    m, n = X.shape\n",
        "    \n",
        "    all_theta = np.zeros((num_labels, n + 1))\n",
        "\n",
        "    # Agrega unos a la matriz X\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "\n",
        "    for c in np.arange(num_labels):\n",
        "        initial_theta = np.zeros(n + 1)\n",
        "        options = {'maxiter': 50}\n",
        "        res = optimize.minimize(lrCostFunction, \n",
        "                                initial_theta, \n",
        "                                (X, (y == c), lambda_), \n",
        "                                jac=True, \n",
        "                                method='CG',\n",
        "                                options=options) \n",
        "        \n",
        "        all_theta[c] = res.x\n",
        "\n",
        "    return all_theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ENrPy8YhaSAl"
      },
      "outputs": [],
      "source": [
        "lambda_ = 0.1\n",
        "all_theta = oneVsAll(X, y, num_labels, lambda_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnvVKBmhaSAl"
      },
      "source": [
        "<a id=\"section3\"></a>\n",
        "#### 1.4.1 Prediccion One-vs-all\n",
        "\n",
        "Después de entrenar el clasificador de one-vs-all, se puede usarlo para predecir el dígito contenido en una imagen determinada. Para cada entrada, debe calcular la \"probabilidad\" de que pertenezca a cada clase utilizando los clasificadores de regresión logística entrenados. La función de predicción one-vs-all seleccionará la clase para la cual el clasificador de regresión logística correspondiente genera la probabilidad más alta y devolverá la etiqueta de clase (0, 1, ..., K-1) como la predicción para el ejemplo de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0cAGDUSYaSAl"
      },
      "outputs": [],
      "source": [
        "def predictOneVsAll(all_theta, X):\n",
        "    \"\"\"\n",
        "    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n",
        "    Tenga en cuenta que X contiene los ejemplos en filas. \n",
        "    all_theta es una matriz donde la i-ésima fila es un vector theta de regresión logística entrenada para la i-ésima clase. \n",
        "    Debe establecer p en un vector de valores de 0..K-1 (por ejemplo, p = [0, 2, 0, 1] \n",
        "    predice clases 0, 2, 0, 1 para 4 ejemplos).\n",
        "    \n",
        "    Parametros\n",
        "    ----------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        and n is number of features without the bias.\n",
        "    \n",
        "    X : array_like\n",
        "        Data points to predict their labels. This is a matrix of shape \n",
        "        (m x n) where m is number of data points to predict, and n is number \n",
        "        of features without the bias term. Note we add the bias term for X in \n",
        "        this function. \n",
        "    \n",
        "    Devuelve\n",
        "    -------\n",
        "    p : array_like\n",
        "        The predictions for each data point in X. This is a vector of shape (m, ).\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[0];\n",
        "    num_labels = all_theta.shape[0]\n",
        "\n",
        "    p = np.zeros(m)\n",
        "\n",
        "    # Add ones to the X data matrix\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDznNGAZaSAl"
      },
      "source": [
        "Una vez que haya terminado, se llama a la función `predictOneVsAll` usando el valor aprendido de $\\theta$. Debería apreciarse que la precisión del conjunto de entrenamiento es de aproximadamente 95,1% (es decir, clasifica correctamente el 95,1% de los ejemplos del conjunto de entrenamiento)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_AqIYLaNaSAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618292b7-6940-4b57-e1bb-1bdfc13ca32b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 13)\n",
            "Precision del conjuto de entrenamiento: 70.32%\n",
            "(1, 13)\n",
            "(1, 14)\n",
            "[2]\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "pred = predictOneVsAll(all_theta, X)\n",
        "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y) * 100))\n",
        "XPrueba = X[4002:4003, :].copy()\n",
        "print(XPrueba.shape)\n",
        "#print(np.ones((1)))\n",
        "#print(XPrueba)\n",
        "#p = np.zeros(1)\n",
        "XPrueba = np.concatenate([np.ones((1, 1)), XPrueba], axis=1)\n",
        "print(XPrueba.shape)\n",
        "p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n",
        "print(p)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}